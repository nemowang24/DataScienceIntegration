<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Audio Visualization</title>
    <style>
        canvas {
            display: block;
            margin: 20px auto;
            border: 1px solid #ccc;
        }
    </style>
</head>
<body>
<h1>Real-Time Audio Data</h1>
<button id="startRecording">Start</button>
<button id="stopRecording" disabled>Stop</button>
<canvas id="audioVisualizer" width="800" height="200"></canvas>

<script>
    const startButton = document.getElementById('startRecording');
    const stopButton = document.getElementById('stopRecording');
    const canvas = document.getElementById('audioVisualizer');
    const canvasCtx = canvas.getContext('2d');

    let audioContext, analyser, microphone, dataArray, animationFrame;

    startButton.onclick = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

            // Create an AudioContext
            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 22050 });

            // Create an analyser node
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048; // Number of data points used for the FFT
            const bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            // Connect the microphone to the analyser
            microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);

            // Start visualizing
            startButton.disabled = true;
            stopButton.disabled = false;

            visualize();
        } catch (error) {
            console.error('Error accessing audio stream:', error);
            alert('Could not access your microphone.');
        }
    };

    stopButton.onclick = () => {
        audioContext.close();  // Close the audio context
        cancelAnimationFrame(animationFrame); // Stop visualization loop

        startButton.disabled = false;
        stopButton.disabled = true;

        // Reset canvas
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
    };

    function visualize() {
        animationFrame = requestAnimationFrame(visualize);

        analyser.getByteTimeDomainData(dataArray);

        // Draw the waveform
        canvasCtx.fillStyle = '#f4f4f4';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = '#007bff';
        canvasCtx.beginPath();

        const sliceWidth = canvas.width / dataArray.length;
        let x = 0;

        for (let i = 0; i < dataArray.length; i++) {
            const v = dataArray[i] / 128.0;
            const y = (v * canvas.height) / 2;

            if (i === 0) {
                canvasCtx.moveTo(x, y);
            } else {
                canvasCtx.lineTo(x, y);
            }

            x += sliceWidth;
        }

        canvasCtx.lineTo(canvas.width, canvas.height / 2);
        canvasCtx.stroke();
    }
</script>
</body>
</html>